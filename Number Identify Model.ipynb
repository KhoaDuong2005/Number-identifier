{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83255466-2890-496b-80e3-00c9b07e1710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastbook import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72908561-1c9b-4244-866b-311eb3003236",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST) #Download the whole number datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f8ae305-e1d1-40d3-a5c2-3addd095d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"C:/Users/Administrator/.fastai/data/mnist_png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c7da19-4ca1-48f9-8e71-97d3bb60d6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('C:/Users/Administrator/.fastai/data/mnist_png/training/0'),Path('C:/Users/Administrator/.fastai/data/mnist_png/training/1'),Path('C:/Users/Administrator/.fastai/data/mnist_png/training/2'),Path('C:/Users/Administrator/.fastai/data/mnist_png/training/3'),Path('C:/Users/Administrator/.fastai/data/mnist_png/training/4'),Path('C:/Users/Administrator/.fastai/data/mnist_png/training/5'),Path('C:/Users/Administrator/.fastai/data/mnist_png/training/6'),Path('C:/Users/Administrator/.fastai/data/mnist_png/training/7'),Path('C:/Users/Administrator/.fastai/data/mnist_png/training/8'),Path('C:/Users/Administrator/.fastai/data/mnist_png/training/9')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/\"training\").ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6553cfd2-cff8-44d9-9b96-b8413b0a71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = (path/\"training\"/\"0\").ls().sorted()\n",
    "ones = (path/\"training\"/\"1\").ls().sorted()\n",
    "twos = (path/\"training\"/\"2\").ls().sorted()\n",
    "threes = (path/\"training\"/\"3\").ls().sorted()\n",
    "fours = (path/\"training\"/\"4\").ls().sorted()\n",
    "fives = (path/\"training\"/\"5\").ls().sorted()\n",
    "sixs = (path/\"training\"/\"6\").ls().sorted()\n",
    "sevens = (path/\"training\"/\"7\").ls().sorted()\n",
    "eights = (path/\"training\"/\"8\").ls().sorted()\n",
    "nines = (path/\"training\"/\"9\").ls().sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c53488a-5c69-4c02-8a33-20c4f53b78fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_tensor = [tensor(Image.open(o)) for o in zeros]\n",
    "ones_tensor = [tensor(Image.open(o)) for o in ones]\n",
    "twos_tensor = [tensor(Image.open(o)) for o in twos]\n",
    "threes_tensor = [tensor(Image.open(o)) for o in threes]\n",
    "fours_tensor = [tensor(Image.open(o)) for o in fours]\n",
    "fives_tensor = [tensor(Image.open(o)) for o in fives]\n",
    "sixs_tensor = [tensor(Image.open(o)) for o in sixs]\n",
    "sevens_tensor = [tensor(Image.open(o)) for o in sevens]\n",
    "eights_tensor = [tensor(Image.open(o)) for o in eights]\n",
    "nines_tensor = [tensor(Image.open(o)) for o in nines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73405e7b-cad3-4c31-8fa4-d92734a356e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_zeros = torch.stack(zeros_tensor).float()/255\n",
    "stacked_ones = torch.stack(ones_tensor).float()/255\n",
    "stacked_twos = torch.stack(twos_tensor).float()/255\n",
    "stacked_threes = torch.stack(threes_tensor).float()/255\n",
    "stacked_fours = torch.stack(fours_tensor).float()/255\n",
    "stacked_fives = torch.stack(fives_tensor).float()/255\n",
    "stacked_sixs = torch.stack(sixs_tensor).float()/255\n",
    "stacked_sevens = torch.stack(sevens_tensor).float()/255\n",
    "stacked_eights = torch.stack(eights_tensor).float()/255\n",
    "stacked_nines = torch.stack(nines_tensor).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee944cc7-d7be-457a-933c-969c16e1fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = [stacked_zeros, stacked_ones, stacked_twos, stacked_threes, \n",
    "              stacked_fours, stacked_fives, stacked_sixs, stacked_sevens, \n",
    "              stacked_eights, stacked_nines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d964a2-2b26-4a15-8737-48322d049730",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat(all_images).view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d0a7c11-dbbd-4e8a-8b3c-c68125e835ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape #This conclude total 60 thousands image from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6044fe6f-c602-4b42-af98-73aac64a7be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = tensor(\n",
    "    [0] * len(zeros) + \n",
    "    [1] * len(ones) + \n",
    "    [2] * len(twos) +\n",
    "    [3] * len(threes) + \n",
    "    [4] * len(fours) + \n",
    "    [5] * len(fives) + \n",
    "    [6] * len(sixs) + \n",
    "    [7] * len(sevens) + \n",
    "    [8] * len(eights) + \n",
    "    [9] * len(nines)\n",
    ").unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cfdac02-cf82-4b06-b68d-a2bb1cba06b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f7177c4-9fc5-41e4-93bf-87dc9c5dcc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(train_x, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18f4ef10-422f-4666-9321-1bef8611d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_zeros = [tensor(Image.open(o)) for o in (path/\"testing\"/\"0\").ls()]\n",
    "valid_ones = [tensor(Image.open(o)) for o in (path/\"testing\"/\"1\").ls()]\n",
    "valid_twos = [tensor(Image.open(o)) for o in (path/\"testing\"/\"2\").ls()]\n",
    "valid_threes = [tensor(Image.open(o)) for o in (path/\"testing\"/\"3\").ls()]\n",
    "valid_fours = [tensor(Image.open(o)) for o in (path/\"testing\"/\"4\").ls()]\n",
    "valid_fives = [tensor(Image.open(o)) for o in (path/\"testing\"/\"5\").ls()]\n",
    "valid_sixs = [tensor(Image.open(o)) for o in (path/\"testing\"/\"6\").ls()]\n",
    "valid_sevens = [tensor(Image.open(o)) for o in (path/\"testing\"/\"7\").ls()]\n",
    "valid_eights = [tensor(Image.open(o)) for o in (path/\"testing\"/\"8\").ls()]\n",
    "valid_nines = [tensor(Image.open(o)) for o in (path/\"testing\"/\"9\").ls()]\n",
    "\n",
    "valid_zeros = torch.stack(valid_zeros).float()/255\n",
    "valid_ones = torch.stack(valid_ones).float()/255\n",
    "valid_twos = torch.stack(valid_twos).float()/255\n",
    "valid_threes = torch.stack(valid_threes).float()/255\n",
    "valid_fours = torch.stack(valid_fours).float()/255\n",
    "valid_fives = torch.stack(valid_fives).float()/255\n",
    "valid_sixs = torch.stack(valid_sixs).float()/255\n",
    "valid_sevens = torch.stack(valid_sevens).float()/255\n",
    "valid_eights = torch.stack(valid_eights).float()/255\n",
    "valid_nines = torch.stack(valid_nines).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09c6d97e-873b-46ea-a708-52248d0daf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = [valid_zeros, valid_ones, valid_twos, valid_threes, \n",
    "              valid_fours, valid_fives, valid_sixs, valid_sevens, \n",
    "              valid_eights, valid_nines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b2bba5a-d06a-475c-a8ac-94390c45c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat(all_images).view(-1, 28*28)\n",
    "valid_y = tensor(\n",
    "    [0] * len(valid_zeros) + \n",
    "    [1] * len(valid_ones) + \n",
    "    [2] * len(valid_twos) +\n",
    "    [3] * len(valid_threes) + \n",
    "    [4] * len(valid_fours) + \n",
    "    [5] * len(valid_fives) + \n",
    "    [6] * len(valid_sixs) + \n",
    "    [7] * len(valid_sevens) + \n",
    "    [8] * len(valid_eights) + \n",
    "    [9] * len(valid_nines)\n",
    ").unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0b4a6390-8977-4e1a-bd8e-e190c4621b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "45f31fb0-6f7b-44ea-810a-1c74a367839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std = 1.0): # Take the size and set standard deviation to 1.0\n",
    "    return (torch.randn(size)*std).requires_grad_() # Make a random number of size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "12e33b04-7323-49d3-98c7-0c107f2988fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28, 10)) # Initialize the weight and bias\n",
    "bias = init_params(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "1f3dcd1d-cd9c-432c-9fbd-d4f74437e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "1834ee2a-efb9-4226-9f2d-27e86635ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7b6cafc5-c5de-4415-9787-6c8f4cce4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c4ceb66e-577e-4d74-8c62-1776c42794b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    targets = targets.long()\n",
    "    targets = targets.squeeze()\n",
    "    return F.cross_entropy(predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5ecd69f3-7f07-4f3a-949f-8e197c4c4928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model): # Calculate the gradient for the model and return it\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d81f7913-07a4-462b-81a3-5829035030d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear1(xb):\n",
    "    return xb@weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "d6034235-c913-48ec-b183-6119abc52322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb, yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad * lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "98e62b84-6cdf-4d8d-bfd8-421aa12be37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    # Apply softmax to get probabilities for each class (0-9)\n",
    "    preds = torch.softmax(xb, dim=1)\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    _, predicted_classes = torch.max(preds, dim=1)\n",
    "    \n",
    "    # Check if the predicted class matches the true class\n",
    "    corrects = (predicted_classes == yb)\n",
    "    \n",
    "    # Return the mean accuracy\n",
    "    return corrects.float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "7a3b4270-c9b9-4b81-b6a1-fc10095cac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    acs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(acs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d6dd4564-9480-4792-9530-fb65bc48c7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1485"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "68a396ec-810a-4ba1-aea1-9aef1434aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c4748f1b-4aab-486b-b013-9da12b56357c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2038"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = weights, bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd2965-07a3-45ee-b01c-851dbba28f53",
   "metadata": {},
   "source": [
    "# Try this with a BasicOptimizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "4341eb21-0bff-4970-abb3-820b51dd0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "b819cef2-5806-4aa2-be32-c35bff5f3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(28*28, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "e6b2aeac-30f5-4997-a565-ed0e7b85ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = linear_model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "6741fd2a-f446-4d76-b74c-f6b5ab99db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params:\n",
    "            p.data -= p.grad.data * self.lr\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "9115d8af-6ff6-4358-9f54-141c51cddeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BasicOptim(linear_model.parameters(), lr)\n",
    "\n",
    "# Now we can simplify our trainning epoch like this:\n",
    "def train_epoch(model):\n",
    "    for xb, yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "aaeb319a-a579-43de-abec-79709d627d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epoch):\n",
    "    for i in range(epoch):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "2ff8eefa-b2bf-4fc8-acf6-f81e0ba94804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.61613130569458\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[288], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinear1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[287], line 3\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, epoch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_model\u001b[39m(model, epoch):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[1;32m----> 3\u001b[0m         \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(validate_epoch(model), end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[286], line 7\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m dl:\n\u001b[0;32m      6\u001b[0m     calc_grad(xb, yb, model)\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[1;32mIn[285], line 8\u001b[0m, in \u001b[0;36mBasicOptim.step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams:\n\u001b[1;32m----> 8\u001b[0m         p\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "train_model(linear1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "73b4c5c4-876a-407f-a5f4-3de39952bd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2514 0.4138 0.5224 0.5907 0.6412 0.6741 0.6994 0.7158 0.7299 0.7406 0.7488 0.7555 0.7619 0.7658 0.7683 0.7726 0.7758 0.7795 0.7826 0.7852 "
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,10)\n",
    "opt = SGD(linear_model.parameters(), lr)\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "62d80a67-8bfc-4e9e-8c27-ef44bf8963ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl, valid_dl)\n",
    "learn = Learner(dls, nn.Linear(28*28,10), opt_func=SGD,\n",
    "loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "a35904c5-ea5a-44dd-8d13-7fca0b26b9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.108814</td>\n",
       "      <td>1.999956</td>\n",
       "      <td>0.214613</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.737348</td>\n",
       "      <td>1.721633</td>\n",
       "      <td>0.393536</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.517402</td>\n",
       "      <td>1.497129</td>\n",
       "      <td>0.508959</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.362359</td>\n",
       "      <td>1.327689</td>\n",
       "      <td>0.580916</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.245664</td>\n",
       "      <td>1.199273</td>\n",
       "      <td>0.627934</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.154837</td>\n",
       "      <td>1.099801</td>\n",
       "      <td>0.666130</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.082347</td>\n",
       "      <td>1.020905</td>\n",
       "      <td>0.689165</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.023248</td>\n",
       "      <td>0.956957</td>\n",
       "      <td>0.707346</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.974167</td>\n",
       "      <td>0.904128</td>\n",
       "      <td>0.721103</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.932745</td>\n",
       "      <td>0.859758</td>\n",
       "      <td>0.730814</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.897298</td>\n",
       "      <td>0.821957</td>\n",
       "      <td>0.740246</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.866591</td>\n",
       "      <td>0.789353</td>\n",
       "      <td>0.749395</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.839709</td>\n",
       "      <td>0.760926</td>\n",
       "      <td>0.755291</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.815956</td>\n",
       "      <td>0.735908</td>\n",
       "      <td>0.760243</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.794796</td>\n",
       "      <td>0.713706</td>\n",
       "      <td>0.765438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.775809</td>\n",
       "      <td>0.693858</td>\n",
       "      <td>0.769941</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.758663</td>\n",
       "      <td>0.675997</td>\n",
       "      <td>0.773942</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.743090</td>\n",
       "      <td>0.659832</td>\n",
       "      <td>0.776914</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.728872</td>\n",
       "      <td>0.645122</td>\n",
       "      <td>0.779694</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.715832</td>\n",
       "      <td>0.631674</td>\n",
       "      <td>0.782142</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(20, lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04a2b9f-b8ae-4647-9cf3-3b3100a9c516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
